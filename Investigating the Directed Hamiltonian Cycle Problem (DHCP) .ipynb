{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating the Directed Hamiltonian Cycle Problem (DHCP)\n",
    "Olivia Qader\n",
    "\n",
    "Avaliable on GitHub: https://github.coventry.ac.uk/380CT-1718JANMAY/380CT-Hamiltonian-Cycle \n",
    "\n",
    "## Notation\n",
    "The notation will be set for this investigation by the use of $x_1,x_2,\\ldots,x_n$ as graph vertices with $G$ representing the graph so when fulfilling the right conditions this should display that\n",
    " $$  G = x_1,x_2,\\ldots,x_1,\n",
    " $$ where $x_1$ is the starting and ending vertex of the graph. Each vertex that is not $x_1$ should be visited only once.\n",
    " \n",
    "The degree of $x_n$ will be shown as $d_n$ and Directed Paths will be set as $P_1, \\ldots , P_n$ with length equal to $2d_1, \\ldots, 2d_n.$\n",
    "\n",
    "\n",
    "## Definition of the Problem\n",
    "The problem which I will be investigating in this study is the Directed Hamiltonian Cycle Problem which refers to the context of a directed graph and the reqirements that it must be decided if the path visits every vertex exactly once and terminates at the same vertex at which it started. If it does not satisfy both conditions, it cannot be classed as a Hamiltonian Cycle.\n",
    "\n",
    "DHCP is an NP-Complete problem as it can be verified in polynomial time and fulfills the conditions to be both NP and NP-Hard, making it NP-Complete. It was among the first problems to be found NP-complete as the decision version of HCP (Reducibility Among Combinatorial Problems 1972) and has many applications which cause the study of the problem to continue today.\n",
    "\n",
    "## Testing Methodology\n",
    "**Exhaustive Search** : Goes through all possible results in a determined order. Average time for instances increases with $n$\n",
    "\n",
    "**Greedy Algorithm** : Goes through the highest values until it has completed. Average time for instances is $O$($n$ $log$ $n$)\n",
    "\n",
    "**Meta-Heuristics** : As for Meta-Heuristic algorithms, a genetic algorithm has been chosen. This is a type of algorithm which evolves to the best solution through the crossover and mutation operation. (Schmitt, L. J., & Amini, M. M. 1998)\n",
    "\n",
    "**Special Cases** : Refers to instances which can be solved exactly in polynomial time. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Code\n",
    "During the code process, it was worked upon as a group between myself, Chris Mander and Samathy Barratt. We have worked to complete code together over a period of time including organised group code session meetings and using a shared GitHub repository.\n",
    "\n",
    "## Base \n",
    "The basis of each algorithm is based upon code which generates an adjacency matrix that will be tested through each approach to determine if it fits the requirements of the Hamiltonian Cycle. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint, choice\n",
    "\n",
    "class AdjacencyMatrix:\n",
    "    \"\"\" Contains adjacency matrix representing graph \"\"\"\n",
    "    def __init__(self):\n",
    "        self.matrix = []\n",
    "        self.node_count = 0\n",
    "\n",
    "    def fromList(self, givenList):\n",
    "        self.matrix = givenList\n",
    "\n",
    "        return self\n",
    "\n",
    "    def generate_matrix(self, node_count):\n",
    "        \"\"\"Returns a randomly filled matrix\"\"\"\n",
    "        self.node_count = node_count\n",
    "\n",
    "        for i in range(0, node_count):\n",
    "            self.matrix.append(self.generate_row(i, node_count))\n",
    "\n",
    "        \"\"\"Remove all nodes that point to themselves.\"\"\"\n",
    "        for i in range(0, node_count):\n",
    "            self.matrix[i][i] = 0\n",
    "\n",
    "        return self\n",
    "\n",
    "    def removeSelfReferences(self):\n",
    "\n",
    "        \"\"\"Remove all nodes that point to themselves.\"\"\"\n",
    "        for i in range(0, self.node_count):\n",
    "            self.matrix[i][i] = 0\n",
    "\n",
    "    def generate_row(self, index, node_count):\n",
    "        \"\"\"Ensures that each row contains atleast a single 1 for connectedness.\"\"\"\n",
    "        row = [0 for i in range(0, node_count)]\n",
    "        valid_row = False\n",
    "        \n",
    "        while not valid_row:\n",
    "            for i in range(0, node_count):\n",
    "                row[i] = choice([0, 1])\n",
    "                if row[i] == 1:\n",
    "                    valid_row = True\n",
    "\n",
    "        return row\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "\n",
    "        return self.matrix[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.matrix)\n",
    "\n",
    "    def index(self, index):\n",
    "        return self.matrix.index(index)\n",
    "\n",
    "    def pretty_print(self):\n",
    "        print(\" \"+str([i for i in range(len(self.matrix))]))\n",
    "        #print(\"  \"+\"-\"*((len(self.matrix)+2)+6))\n",
    "        for i in range(0, len(self.matrix)):\n",
    "            print(str(i) + str(self.matrix[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Graphs with Run Time metrics\n",
    "\n",
    "This example uses the exhaustive search which will be explored in more detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'adjacency_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d028834f484a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0madjacency_matrix\u001b[0m    \u001b[1;32mimport\u001b[0m \u001b[0mAdjacencyMatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mexhaustive_search\u001b[0m   \u001b[1;32mimport\u001b[0m \u001b[0mExhaustiveSearch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgreedy_search\u001b[0m       \u001b[1;32mimport\u001b[0m \u001b[0mGreedySearch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgenetic_algorithm\u001b[0m   \u001b[1;32mimport\u001b[0m \u001b[0mGeneticAlgorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgreedy_optimised\u001b[0m    \u001b[1;32mimport\u001b[0m \u001b[0mGreedySearchOptimised\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'adjacency_matrix'"
     ]
    }
   ],
   "source": [
    "from adjacency_matrix    import AdjacencyMatrix\n",
    "from exhaustive_search   import ExhaustiveSearch\n",
    "from greedy_search       import GreedySearch\n",
    "from genetic_algorithm   import GeneticAlgorithm\n",
    "from greedy_optimised    import GreedySearchOptimised\n",
    "from simulated_annealing import SimulatedAnnealing\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ex_search  = ExhaustiveSearch()\n",
    "    gr_search  = GreedySearch()\n",
    "    gro_search = GreedySearchOptimised()\n",
    "    sim_anneal = SimulatedAnnealing()\n",
    "    genetic_alg = GeneticAlgorithm()\n",
    "    algorithms = [ex_search, sim_anneal]\n",
    "    \n",
    "    step = 1\n",
    "    min_node_count = 6\n",
    "    max_node_count = 6 + step  # iterations from min to max\n",
    "    instance_count = 1          # number of instances per n-graph\n",
    "    \n",
    "    \"\"\" Generate random graphs. Multidimensional list containing instance_count number of each sized graph.\"\"\"\n",
    "    graph_instances = list()\n",
    "\n",
    "    graph_instances.append([AdjacencyMatrix().generate_matrix(6)])\n",
    "    matrix = graph_instances[0][0].matrix\n",
    "    matrix[0][0] = 0\n",
    "    matrix[0][1] = 1\n",
    "    matrix[0][2] = 1\n",
    "    matrix[0][3] = 1\n",
    "    matrix[0][4] = 0\n",
    "    matrix[0][5] = 0\n",
    "    matrix[1][0] = 0\n",
    "    matrix[1][1] = 0\n",
    "    matrix[1][2] = 0\n",
    "    matrix[1][3] = 1\n",
    "    matrix[1][4] = 0\n",
    "    matrix[1][5] = 0\n",
    "    matrix[2][0] = 1\n",
    "    matrix[2][1] = 1\n",
    "    matrix[2][2] = 0\n",
    "    matrix[2][3] = 0\n",
    "    matrix[2][4] = 1\n",
    "    matrix[2][5] = 0\n",
    "    matrix[3][0] = 1\n",
    "    matrix[3][1] = 0\n",
    "    matrix[3][2] = 0\n",
    "    matrix[3][3] = 0\n",
    "    matrix[3][4] = 0\n",
    "    matrix[3][5] = 1\n",
    "    matrix[4][0] = 0\n",
    "    matrix[4][1] = 1\n",
    "    matrix[4][2] = 1\n",
    "    matrix[4][3] = 1\n",
    "    matrix[4][4] = 0\n",
    "    matrix[4][5] = 0\n",
    "    matrix[5][0] = 1\n",
    "    matrix[5][1] = 0\n",
    "    matrix[5][2] = 1\n",
    "    matrix[5][3] = 0\n",
    "    matrix[5][4] = 0\n",
    "    matrix[5][5] = 0\n",
    "    \n",
    "    \n",
    "    graph_instances[0][0].pretty_print()\n",
    "    \n",
    "    \"\"\" Run algorithm. \"\"\"\n",
    "    for i in algorithms:\n",
    "        i.benchmark(graph_instances)\n",
    "        graph_size = min_node_count\n",
    "        print(\"Algorithm: \"+i.__class__.__name__+\"\\n\")\n",
    "        for j in range(len(i.global_run_times)):\n",
    "            print(\"Vertex Count: \"     + str(graph_size) + \"\\t\" +\n",
    "                  \"Run time: \"         + str(i.global_run_times[j]) + \"\\t\" +\n",
    "                  \"Acceptance ratio: \" + str(i.global_instances[j]))\n",
    "            graph_size += step\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution Methods\n",
    "\n",
    "## Exhaustive Search\n",
    "\n",
    "**Pseudo-code:**\n",
    "\n",
    "For all possible variable assignments of $x_1,x_2,\\ldots,x_n$ in $G$:\n",
    "\n",
    "$\\quad$ if $\\phi = x_1,x_2,\\ldots,x_1$ and total vertices visited = number of vertices in $G + 1$:\n",
    "\n",
    "$\\qquad$ return True\n",
    "\n",
    "$\\quad$ else:\n",
    "\n",
    "$\\qquad$ return False\n",
    "\n",
    "**Cost**\n",
    "The cost of this algorithm increases as $n$ increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Contains class for exhaustive search\n",
    "    Usage:\n",
    "        if ExhaustiveSearch.with_matrix(matrix).is_hamiltonion():\n",
    "            print(\"Is hamiltonion!\")\n",
    "\"\"\"\n",
    "\n",
    "from algorithm import Algorithm\n",
    "\n",
    "class ExhaustiveSearch(Algorithm):\n",
    "    \"\"\"Find a hamiltonion cyclic graph using exhaustive search\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        \"\"\" The following stack stores the previously visited vertices, beginning with\n",
    "        the start vertex stack[0] = node 0 ... stack[n] = node n \"\"\"\n",
    "        self.stack = []\n",
    "\n",
    "        \"\"\" The following list stores all vertices in the list. Each vertex is removed\n",
    "        when visited to ensure that they are visited only once. \"\"\"\n",
    "        self.unvisited_vertices = []        \n",
    "        \n",
    "    def mark_not_visited(self, vertex):\n",
    "        \"\"\" Safely removes vertex from unvisited_vertices and informs of the following:\n",
    "        > returns True if vertex was found and removed. (first visit of vertex)\n",
    "        > returns False if vertex was not found (previously visited)\"\"\"\n",
    "        if vertex in self.unvisited_vertices:\n",
    "            self.unvisited_vertices.remove(vertex)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def is_hamiltonian(self, matrix):\n",
    "        lookup_table = dict()\n",
    "        for i in range(len(matrix)):\n",
    "            lookup_table[i] = [matrix[i][j] for j in range(len(matrix))]\n",
    "            \n",
    "        self.stack = [0]\n",
    "        \n",
    "        \"\"\" Reference for current vertex. \"\"\"\n",
    "        current_vertex = self.stack[-1]\n",
    "        path = [current_vertex]\n",
    "        roll_back = False\n",
    "        \n",
    "        while True:\n",
    "            if (len(self.stack) == len(matrix)):\n",
    "                if matrix[self.stack[-1]][0] == 1:\n",
    "                    return True\n",
    "                else:\n",
    "                    roll_back = True\n",
    "                        \n",
    "            if (sum(lookup_table[0]) == 0):\n",
    "                \"\"\" All paths from vertex 0 explored; therefore graph exhausted. \"\"\"\n",
    "                return False    \n",
    "                \n",
    "            if sum(lookup_table[current_vertex]) > 0:\n",
    "                available_edges = False\n",
    "                for i in range(len(lookup_table[current_vertex])):\n",
    "                    if i in self.stack:\n",
    "                        lookup_table[current_vertex][i] = 0\n",
    "                    if lookup_table[current_vertex][i] == 1:\n",
    "                        lookup_table[current_vertex][i] = 0\n",
    "                        current_vertex = i\n",
    "                        self.stack.append(current_vertex)\n",
    "                        available_edges = True\n",
    "                        break\n",
    "                if not available_edges:\n",
    "                    roll_back = True\n",
    "            else:\n",
    "                roll_back = True\n",
    "\n",
    "            if roll_back:    \n",
    "                \"\"\" Reset row to allow entry from other vertices. \"\"\"\n",
    "                lookup_table[current_vertex] = matrix[current_vertex]\n",
    "                self.stack.pop()\n",
    "                current_vertex = self.stack[-1]\n",
    "                roll_back = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing \n",
    "\n",
    "Testing for randomly generated adjacency matrix graphs using the exhaustive search.\n",
    "\n",
    "Vertex Count: 10\tRun time: 57.0\tAcceptance ratio: 0.8\n",
    "\n",
    "Vertex Count: 15\tRun time: 145.0\tAcceptance ratio: 0.5\n",
    "\n",
    "Vertex Count: 20\tRun time: 227.0\tAcceptance ratio: 0.3\n",
    "\n",
    "Vertex Count: 25\tRun time: 358.5\tAcceptance ratio: 0.4\n",
    "\n",
    "Vertex Count: 30\tRun time: 532.0\tAcceptance ratio: 0.2\n",
    "\n",
    "Vertex Count: 35\tRun time: 687.0\tAcceptance ratio: 0.3\n",
    "\n",
    "Vertex Count: 40\tRun time: 881.0\tAcceptance ratio: 0.3\n",
    "\n",
    "Vertex Count: 45\tRun time: 1130.5\tAcceptance ratio: 0.6\n",
    "\n",
    "Vertex Count: 50\tRun time: 1306.0\tAcceptance ratio: 0.8\n",
    "\n",
    "Vertex Count: 55\tRun time: 1541.0\tAcceptance ratio: 0.6\n",
    "\n",
    "Vertex Count: 60\tRun time: 1909.0\tAcceptance ratio: 0.3\n",
    "\n",
    "Vertex Count: 65\tRun time: 2217.5\tAcceptance ratio: 0.3\n",
    "\n",
    "Vertex Count: 70\tRun time: 2528.0\tAcceptance ratio: 0.4\n",
    "\n",
    "Vertex Count: 75\tRun time: 2941.0\tAcceptance ratio: 0.6\n",
    "\n",
    "Vertex Count: 80\tRun time: 3281.0\tAcceptance ratio: 0.3\n",
    "\n",
    "Vertex Count: 85\tRun time: 3732.5\tAcceptance ratio: 0.5\n",
    "\n",
    "Vertex Count: 90\tRun time: 4186.0\tAcceptance ratio: 0.6\n",
    "\n",
    "Vertex Count: 95\tRun time: 4789.0\tAcceptance ratio: 0.5\n",
    "\n",
    "Vertex Count: 100\tRun time: 5121.0\tAcceptance ratio: 0.5\n",
    "\n",
    "## Discussion\n",
    "1. Run time grows greatly as vertex count increases.\n",
    "2. Due to the expensive run time as the vertex count increases, this algorithm is more suited towards smaller graphs. \n",
    "3. Exceptance ratio can be seen to peak at a vertex count of 10 and 50, although it is likely that 50 is an exception instead of a rule as exceptance is more likely at a lower vertex count statistically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy\n",
    "\n",
    "Greedy Algorithm sorts $x_1, x_2 \\ldots, x_n$ by value and selects the one with the largest value.  It will recursively solve the problem by going through this process and picking the highest avaliable value of $x$ in that order.\n",
    "\n",
    "**Pseudo-Code**:\n",
    "\n",
    "for $x$ in $G$:\n",
    "\n",
    "$ \\quad$ if sum of $G(x)$ > highest $d$:\n",
    "\n",
    "$ \\qquad$ if $x$ is not an unvisited vertex:\n",
    "\n",
    "$ \\qquad \\quad$ continue\n",
    "\n",
    "$ \\qquad$ highest degree = sum of G $G(x)$\n",
    "\n",
    "$ \\qquad$ visit next vertex\n",
    "\n",
    "$ \\qquad$ number of vertices visited += 1 \n",
    "\n",
    "$ \\qquad $ if number of unvisited vertices = 0:\n",
    "\n",
    "$\\qquad \\quad $ if $G(x_n)$ = starting vertex:\n",
    "\n",
    "$ \\qquad \\qquad $ return True\n",
    "\n",
    "$ \\qquad \\quad $ else:\n",
    "\n",
    "$ \\qquad \\qquad $ return False\n",
    "\n",
    "\n",
    "**Cost:**\n",
    "\n",
    "The cost of this algorithm is $O$($n$ $log$ $n$) as time goes up linearly and $n$ goes up exponentially using this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithm import Algorithm\n",
    "\n",
    "class GreedySearch(Algorithm):\n",
    "    \"\"\"Decide hamiltonian cycle problem using greedy search heuristic.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.unvisited_vertices = []\n",
    "\n",
    "    def clear_members(self):\n",
    "        self.unvisited_vertices = []\n",
    "        self.visited_vertices = 0\n",
    "\n",
    "    def is_hamiltonian(self, matrix):\n",
    "        \"\"\" Clear timer. \"\"\"\n",
    "        self.timer.vertices_visited = 1\n",
    "        self.clear_members()\n",
    "        if (len(matrix) < 2):\n",
    "            return False\n",
    "\n",
    "        \"\"\" Initialise member variables for run on current matrix. \"\"\"\n",
    "        self.unvisited_vertices = [i for i in range(1, len(matrix))]\n",
    "\n",
    "        \"\"\" Reference for current_vertex. \"\"\"\n",
    "        current_vertex = 0\n",
    "        \n",
    "        while(True):\n",
    "            \"\"\" Used to determine which node to visit next. Qualifying node has\n",
    "            the most out degrees. \"\"\"\n",
    "            next_vertex = 0\n",
    "            highest_degree = 0\n",
    "            \n",
    "            for i in range(len(matrix)):\n",
    "                if matrix[current_vertex][i] == 1:\n",
    "                    if sum(matrix[i]) > highest_degree:\n",
    "                        if i not in self.unvisited_vertices:\n",
    "                            continue\n",
    "                        highest_degree = sum(matrix[i])\n",
    "                        next_vertex = i\n",
    "                        self.timer.vertices_visited += 1\n",
    "\n",
    "            if highest_degree == 0:\n",
    "                \"\"\" Dead end. \"\"\"\n",
    "                return False\n",
    "            \n",
    "            current_vertex = next_vertex\n",
    "            self.unvisited_vertices.remove(current_vertex)\n",
    "\n",
    "            if len(self.unvisited_vertices) == 0:\n",
    "                if matrix[current_vertex][0] == 1:\n",
    "                    \"\"\" Hamiltonian circuit. \"\"\"\n",
    "                    return True\n",
    "                else:\n",
    "                    return False        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Testing for randomly generated adjacency matrix graphs using the greedy search.\n",
    "\n",
    "Vertex Count: 10\tRun time: 22.7\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 15\tRun time: 50.3\tAcceptance ratio: 0.1\n",
    "\n",
    "Vertex Count: 20\tRun time: 81.5\tAcceptance ratio: 0.1\n",
    "\n",
    "Vertex Count: 25\tRun time: 111.6\tAcceptance ratio: 0.1\n",
    "\n",
    "Vertex Count: 30\tRun time: 152.7\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 35\tRun time: 208.6\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 40\tRun time: 243.9\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 45\tRun time: 293.1\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 50\tRun time: 345.4\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 55\tRun time: 380.0\tAcceptance ratio: 0.1\n",
    "\n",
    "Vertex Count: 60\tRun time: 347.3\tAcceptance ratio: 0.3\n",
    "\n",
    "Vertex Count: 65\tRun time: 502.6\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 70\tRun time: 522.4\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 75\tRun time: 595.4\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 80\tRun time: 632.7\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 85\tRun time: 641.2\tAcceptance ratio: 0.1\n",
    "\n",
    "Vertex Count: 90\tRun time: 693.8\tAcceptance ratio: 0.1\n",
    "\n",
    "Vertex Count: 95\tRun time: 820.5\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 100\tRun time: 858.6\tAcceptance ratio: 0.1\n",
    "\n",
    "## Discussion\n",
    "1. Using a greedy algorithm has a more efficient runtime but a lower acceptance ratio overall when used on a Directed Graph in an attempt to find a Hamiltonian Cycle.\n",
    "2. Compared to the expensive run time of exhaustive search at 100 vertices, it may be preferrable to use the greedy approach when $n$ number of $x$ is large. \n",
    "3. However this may lower accuracy as the best route for DHCP is not necessarily taking the path of the largest values. \n",
    "\n",
    "## Genetic Algorithm \n",
    "Genetic Algorithm has been selected as a meta-heuristic solution for the Directed Hamiltonian Cycle problem. \n",
    "\n",
    "**Pseudo-Code:**\n",
    "\n",
    "Initialise population of $G$\n",
    "\n",
    "Evaluate population of $G$\n",
    "\n",
    "while(!stopCondition):\n",
    "\n",
    "$ \\quad $ for candidate in $G$:\n",
    "\n",
    "$ \\qquad $ split and insert offspring into new list of $x$\n",
    "\n",
    "$ \\qquad $ if new offspring longest($n$) = total of $G$ - 1:\n",
    "\n",
    "$ \\qquad \\quad $ break\n",
    "\n",
    "$ \\quad $ Mutate offspring in new list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithm import Algorithm\n",
    "from random import randint\n",
    "\n",
    "class cycle:\n",
    "\n",
    "    nodes = list()\n",
    "\n",
    "    def __init__(self, matrix=None):\n",
    "\n",
    "        self.invalid = False \n",
    "\n",
    "        if (matrix == None):\n",
    "            return\n",
    "\n",
    "        self.search_vertices_visited = []\n",
    "        \n",
    "        if (matrix !=None):\n",
    "            self.generateCycle(matrix)\n",
    "    \n",
    "    def fromList(self, l):\n",
    "        self.nodes = l\n",
    "        return self\n",
    "\n",
    "    def generateCycle(self , matrix, startNode=None, existingCycle=None):\n",
    "\n",
    "        foundStartNode = False\n",
    "\n",
    "        if (startNode == None):\n",
    "            startNode = 0 \n",
    "\n",
    "        if (existingCycle != None):\n",
    "            self.search_vertices_visited = existingCycle[:-1]\n",
    "            self.nodes = existingCycle\n",
    "\n",
    "        node =  startNode\n",
    "\n",
    "        hcFound = False\n",
    "\n",
    "        while not hcFound: \n",
    "            self.search_vertices_visited.append(node)\n",
    "\n",
    "            elementsTried = list()\n",
    "            while ( True ):\n",
    "\n",
    "                connectionElement = randint(0,len(matrix[node])-1)\n",
    "                while ( connectionElement in elementsTried):\n",
    "                    if (len(elementsTried) == len(matrix[node])):\n",
    "                        return False\n",
    "\n",
    "                    connectionElement = randint(0,len(matrix[node])-1)\n",
    "\n",
    "                elementsTried.append(connectionElement)\n",
    "\n",
    "                if matrix[node][connectionElement] == 1 and (connectionElement not in self.search_vertices_visited):\n",
    "                    node = connectionElement\n",
    "                    break\n",
    "                elif matrix[node][connectionElement] == 1 and (connectionElement in self.search_vertices_visited):\n",
    "                    if connectionElement == self.search_vertices_visited[0] and self.search_vertices_visited.count(connectionElement) == 1:\n",
    "                        \n",
    "\n",
    "                        hcFound = True\n",
    "                        node = connectionElement\n",
    "                        self.search_vertices_visited.append(node) \n",
    "                        self.nodes = self.search_vertices_visited\n",
    "                        return True \n",
    "                    elif self.search_vertices_visited.count(connectionElement) >0 :\n",
    "                        \n",
    "                        continue\n",
    "                    else:\n",
    "                        return False\n",
    "\n",
    "    def removeDuplicates(self, matrix):\n",
    "\n",
    "        for i in range(0,len(self.nodes)-1):\n",
    "\n",
    "            while (self.nodes.count(self.nodes[i]) >= 2):\n",
    "                if (self.nodes[i] == self.nodes[0] and self.nodes[1:-1].count(self.nodes[i]) >= 1):\n",
    "                    self.nodes = self.nodes[0:-1]\n",
    "                elif (self.nodes[i] == self.nodes[0] and self.nodes[1:-1].count(self.nodes[i]) ==0):\n",
    "                    break\n",
    "                else:\n",
    "                    self.nodes = self.nodes[0:-1]\n",
    "\n",
    "                    while (self.nodes == self.nodes[0:-1]):\n",
    "                        self.nodes = self.nodes[0:-1]\n",
    "\n",
    "            return\n",
    "\n",
    "    def repairStartEnd(self, matrix):\n",
    "\n",
    "        i = len(self.nodes)-1\n",
    "        if ( i <=0):\n",
    "            return True\n",
    "\n",
    "        while (self.nodes[0] != self.nodes[-1]):\n",
    "            if i-1 <= 0:\n",
    "                return False\n",
    "            while ( not self.generateCycle(matrix, startNode = self.nodes[0], existingCycle=self.nodes[0:i-1])):\n",
    "                    if ( i -1 <= 0):\n",
    "                        return False\n",
    "                    i = i -1\n",
    "\n",
    "        return True\n",
    "            \n",
    "\n",
    "    def checkPath(self, matrix):\n",
    "\n",
    "        for i in range(0,len(self.nodes)-2):\n",
    "\n",
    "            if ( i+2 > len(self.nodes)):\n",
    "                return True\n",
    "\n",
    "            if matrix[self.nodes[i]][self.nodes[i+1]] == 1:\n",
    "                continue\n",
    "            else:\n",
    "                j = i\n",
    "                while ( not self.generateCycle(matrix, startNode = self.nodes[0], existingCycle=self.nodes[0:j+1])):\n",
    "                    if ( j -1 < 0):\n",
    "                        return False\n",
    "                    j = j -1\n",
    "                    continue\n",
    "        return True\n",
    "\n",
    "\n",
    "    def repairCycle(self, matrix):\n",
    "        '''\n",
    "        If we are an invalid cycle, try to build a repaired one\n",
    "        no longer than what we were origionaly\n",
    "        '''\n",
    "        for i in range(0,len(self.nodes)-1):\n",
    "\n",
    "            while(self.nodes[1:-1].count(self.nodes[i]) > 1 or self.nodes.count(self.nodes[i]) > 2):\n",
    "                loc = len(self.nodes) - self.nodes[::-1].index(self.nodes[i]) -1\n",
    "                loc = self.nodes[1:-1].index(self.nodes[i])\n",
    "                j = i\n",
    "                while ( not self.generateCycle(matrix, startNode = self.nodes[0], existingCycle=self.nodes[0:loc])):\n",
    "                    if ( j -1 < 0):\n",
    "                        break\n",
    "                    j = j -1\n",
    "                   \n",
    "                return\n",
    "\n",
    "\n",
    "        self.verifyCycle()\n",
    "        return\n",
    "\n",
    "\n",
    "    def verifyCycle(self):\n",
    "\n",
    "        try:\n",
    "            assert(self.nodes[0] == self.nodes[-1])\n",
    "        except:\n",
    "            return False\n",
    "        try:\n",
    "            if ( len(self.nodes) > 1):\n",
    "                assert(len(self.nodes)-1 == len(set(self.nodes)))\n",
    "        except:\n",
    "            return False\n",
    "        if ( len(self.nodes) <= 1 ):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.nodes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.nodes)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.nodes[item]\n",
    "\n",
    "    def __setitem__(self,item, value):\n",
    "        self.nodes[item] = value\n",
    "\n",
    "    def __add__(self, val):\n",
    "        return self.nodes+val\n",
    "\n",
    "    def __radd__(self, val):\n",
    "        return val+self.nodes\n",
    "\n",
    "    def mutate(self, exchangeCycle, numberOfMutatedNodes=2):\n",
    "        '''\n",
    "        Mutate this cycle against another one. Takes a small number of nodes\n",
    "        from the passed in cycle and swaps them with it's own.\n",
    "        No need to check if the cycle is still valid, because an invalid cycle is fine.\n",
    "        ''' \n",
    "\n",
    "        mutatedNodes = [randint(0, min(len(self)-1, len(exchangeCycle)-1)) for n in range(min(len(self),len(exchangeCycle), 2))]\n",
    "       \n",
    "        for node in mutatedNodes:\n",
    "            self.nodes[node] = exchangeCycle[node]\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "class GeneticAlgorithm(Algorithm):\n",
    "\n",
    "    def __init__(self, matrix=None, iterations=10, populationSize=10, selectionProbability=30, crossoverProbability=10, mutationProbability=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.population = list()\n",
    "\n",
    "        self.probabilityMax = 100\n",
    "        \n",
    "        self.iterations = iterations \n",
    "        self.populationSize = populationSize\n",
    "        self.selectionProbability = selectionProbability % self.probabilityMax\n",
    "        self.crossoverProbability = crossoverProbability % self.probabilityMax\n",
    "        self.mutationProbability = mutationProbability   % self.probabilityMax\n",
    "\n",
    "        self.matrix = matrix\n",
    "\n",
    "    def generatePopulation(self, count, matrix):\n",
    "\n",
    "        for i in range(0, count):\n",
    "            self.population.append(cycle(matrix))\n",
    "\n",
    "        return self.population\n",
    "\n",
    "    def selectHCCandidates(self, candidates, selectionProbability, poolSize):\n",
    "\n",
    "        pool = list()\n",
    "        while ( len(pool) < poolSize):\n",
    "            for candidate in candidates:\n",
    "                if randint(0, self.probabilityMax) <= selectionProbability:\n",
    "                    pool.append(candidate)\n",
    "\n",
    "        return pool\n",
    "\n",
    "        return\n",
    "\n",
    "    def getTotalCycleLengths(self, cycleList):\n",
    "\n",
    "        maxLen = 0\n",
    "        for cycle in cycleList:\n",
    "            if len(cycle) > maxLen:\n",
    "                maxLen = len(cycle)\n",
    "\n",
    "        return maxLen\n",
    "\n",
    "\n",
    "    def crossOver(self, parentList, numberOffspring=2):\n",
    "\n",
    "        offspringList = list()\n",
    "        \n",
    "        for j in range (0, int(len(parentList)/4)):\n",
    "\n",
    "            parent1 = parentList[0]\n",
    "            parent2 = parentList[0]\n",
    "\n",
    "            while parent1 == parent2:\n",
    "                parent1 = parentList[randint(0, len(parentList)-1)]\n",
    "                parent2 = parentList[randint(0, len(parentList)-1)]\n",
    "\n",
    "            for n in range (0, numberOffspring):\n",
    "\n",
    "                LHP1 = randint(0, min(len(parent1), len(parent2)))\n",
    "                LHP2 = randint(LHP1, max(len(parent1), len(parent2)))\n",
    "\n",
    "\n",
    "                offspringList.append(cycle().fromList(parent1[0:LHP1]+parent2[LHP1:LHP2]+parent1[LHP2:]))\n",
    "                offspringList.append(cycle().fromList(parent2[0:LHP1]+parent1[LHP1:LHP2]+parent2[LHP2:]))\n",
    "\n",
    "                parentList = parentList+offspringList\n",
    "\n",
    "        return parentList\n",
    "\n",
    "\n",
    "    def compute(self):\n",
    "\n",
    "        population = self.generatePopulation(self.populationSize, self.matrix)\n",
    "\n",
    "        for n in range(0, self.iterations):\n",
    "            candidates = self.selectHCCandidates(population, self.selectionProbability, self.populationSize)\n",
    "            candidates = self.crossOver(candidates)\n",
    "\n",
    "            for cycle in candidates:\n",
    "                if randint(0, self.probabilityMax) <= self.mutationProbability:\n",
    "                    cycle.mutate(candidates[randint(0, len(candidates)-1)])\n",
    "                if ( not cycle.verifyCycle()):\n",
    "                    cycle.removeDuplicates(self.matrix)\n",
    "                    if ( not cycle.verifyCycle()):\n",
    "                        cycle.Invalid = True\n",
    "            candidates = [cycle for cycle in candidates if not cycle.invalid]\n",
    "\n",
    "            longest = (0, None)\n",
    "            for cycle in candidates:\n",
    "                if longest[0] < len(cycle) and cycle.verifyCycle():\n",
    "                    longest = (len(cycle), cycle)\n",
    "\n",
    "            if (longest[0] >= self.matrix.node_count+1):\n",
    "                return candidates\n",
    "\n",
    "        return candidates\n",
    "\n",
    "\n",
    "    def is_hamiltonian(self, matrix, printCycles=False):\n",
    "\n",
    "        self.matrix = matrix\n",
    "\n",
    "        candidates = self.compute()\n",
    "\n",
    "        longest = (0, None)\n",
    "        for cycle in candidates:\n",
    "            if longest[0] < len(cycle):\n",
    "                longest = (len(cycle), cycle)\n",
    "\n",
    "        if (longest[0] >= self.matrix.node_count-1):\n",
    "            if ( printCycles ):\n",
    "                print(\"Genetic: \"+str(longest[1]))\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def runCycle(self, matrix):\n",
    "        c = cycle(matrix)\n",
    "        return c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "Testing for randomly generated adjacency matrix graphs using the genetic algorithm search.\n",
    "\n",
    "Vertex Count: 10\tRun time: 12.6\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 15\tRun time: 21.9\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 20\tRun time: 33.5\tAcceptance ratio: 0.1\n",
    "\n",
    "Vertex Count: 25\tRun time: 44.6\tAcceptance ratio: 0.1\n",
    "\n",
    "Vertex Count: 30\tRun time: 62.1\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 35\tRun time: 78.2\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 40\tRun time: 93.6\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 45\tRun time: 106.2\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 50\tRun time: 128.1\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 55\tRun time: 139.3\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 60\tRun time: 154.2\tAcceptance ratio: 0.3\n",
    "\n",
    "Vertex Count: 65\tRun time: 181.1\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 70\tRun time: 189.2\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 75\tRun time: 213.2\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 80\tRun time: 223.9\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 85\tRun time: 236.1\tAcceptance ratio: 0.1\n",
    "\n",
    "Vertex Count: 90\tRun time: 255.0\tAcceptance ratio: 0.1\n",
    "\n",
    "Vertex Count: 95\tRun time: 291.2\tAcceptance ratio: 0.0\n",
    "\n",
    "Vertex Count: 100\tRun time: 317.6\tAcceptance ratio: 0.1\n",
    "\n",
    "## Discussion\n",
    "1. The genetic algorithm approach has the lowest run time between all of the algorithms tested.\n",
    "2. However the acceptance ratio is low, especially when compared to the exhaustive search method.\n",
    "3. There is not much growth in run time as $n$ number of $x$ increases which means that this is an efficient algorithm for a larger amount of vertices. \n",
    "\n",
    "\n",
    "## Special Cases\n",
    "\n",
    "1 . The optimal special case for solving DHCP would be when the only vertices in $G$ = $x_0$ and $x_1$ \n",
    "\n",
    "This problem can be solved as a Directed Hamiltonian Cycle with certainty by any algorithm. This is the simplest answer to the problem and would result in selecting one starting vertex, moving to the second vertex and then back to the first vertex which would return $True$ for a Hamiltonian Cycle.\n",
    "\n",
    "\n",
    "2 . If the number of vertices in $G$ = 1: \n",
    "\n",
    "As the only vertice would point towards itself, it would not move between vertices but would fit the overall requirements. It would have visited each vertice only once and start and end on the same vertex which technically could class it as $True$ by the Hamiltonian Cycle conditions. It would produce the answer $True$ using algorithms that did not check for the length of visited vertices to be the number of vertices in $G$ + $1$ however, this may not class as a true Hamiltonian Cycle. \n",
    "\n",
    "3 . Tournament Graph (P. Hell and M. Rosenfeld. 1983)\n",
    "\n",
    "A tournament graph on $n$ vertices as a directed graph such as for all $x$ and $y$, precisely one edge $(x, y)$, $(y, x)$ can be found in the graph.\n",
    "\n",
    "During a round robin tournament, each player will have a round against each different player once. You can imagine that each vertex represents a player and each edge represents a match. Using a directed edge $(x, y)$ results that player $x$ will beat player $y$. \n",
    "\n",
    "## Conclusion\n",
    "The main conclusions that I have came to from this study are as following:\n",
    "1. If an instance is a special case, it can be solved in polynomial time. This may be considered optimal as the problem solving becomes simple when identified. \n",
    "2. Exhaustive search produces very consistent results but grows greatly as $n$ increases. It is efficient when $n$ is not too large. \n",
    "3. Greedy was not the least efficient for run time but it was not fast nor producing consistent results. However it may be considered when $n$ is small as an alternative.\n",
    "4. Genetic algorithm is more efficient in run time but less consistent results than the other two algorithms tested. It did not grow greatly in run time with $n$ so it would be useful for large counts of $n$ in comparison to the other algorithms.\n",
    "\n",
    "\n",
    "\n",
    "## Reflection\n",
    "In reflection of this study, I have found that investigating this problem in depth has greatly enhanced my problem solving and logical thinking skills, especially in the areas of scientific and mathematical computing. I have read through insightful sources that have aided me with the knowledge to complete this study and though it was a large and complex task to tackle, I feel that I have successfully managed to meet the objectives and conclusion needed. \n",
    "\n",
    "If I were to approach this a second time, I would try to write shorter algorithms and test the run time to see if the program is more efficient. It would also be beneficial to look more deeply into meta-heuristic techniques and potentially develop it differently. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "R.M. Karp (1972) Reducibility Among Combinatorial Problems. In R.E. Miller, J.W. Thatcher (Eds.): Complexity of Computer Computations, 85-103.New York: Plenum.\n",
    "\n",
    "Schmitt, L. J., & Amini, M. M. (1998) Performance characteristics of alternative genetic algorithmic approaches to the traveling salesman problem using path representation: An empirical study. European Journal of Operational Research, 108(3), 551-570\n",
    "\n",
    "P. Hell and M. Rosenfeld. (1983) The complexity of Finding generalized paths in tournaments. Journal\n",
    "of Algorithms. 303-309.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
